{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36cdef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import logsumexp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9fb56c",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "836061d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.read_csv(\"./data/Q3/mixture1.geno\", header = None)\n",
    "Xnew_df = pd.read_csv(\"./data/Q3/mixture2.geno\", header = None)\n",
    "F_df = pd.read_csv(\"./data/Q3/mixture1.freq\", header = None)\n",
    "Z_df = pd.read_csv(\"./data/Q3/mixture1.ganc\", header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a2772",
   "metadata": {},
   "source": [
    "# implementation M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d7aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X: N by M data matrix\n",
    "#gamma: P(Z_i=k | X_i=x_i, theta) N by K\n",
    "def M_step(X, gamma): \n",
    "    N, M = X.shape\n",
    "    K = gamma.shape[1]\n",
    "    \n",
    "    ######### TODO 3a: modify the following to have meaning updates #########\n",
    "    pis = None #Proportion vector pi: length K\n",
    "    F = matrix(0, M, K) #Frequency matrix F: M by K\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ######### end of modification #########     \n",
    "    return ({\"pis\": pis, \"F\": F})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d4de2",
   "metadata": {},
   "source": [
    "# implementation E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20b3fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X: N by M data matrix\n",
    "#params: a dictionary with two parameters returned from M_step\n",
    "def E_step(X, params, thr = 10**(-8)):\n",
    "    F = params[\"F\"] #Frequency matrix F: M by K\n",
    "    pis = params[\"pis\"] #Proportion vector pi: length K\n",
    "\n",
    "    N, M = X.shape\n",
    "    K = F.shape[1] \n",
    "\n",
    "    ######### TODO 3b: modify the following to have meaning updates #########\n",
    "    #calculate weighted_log_prob: log(P(X_i=x_i | Z_i=k, theta) * P(Z_i=k | theta))\n",
    "    #calcualte log_prob_sample: log P(Xi=x_i | theta) length N vector. Hint: use logsumexp function\n",
    "    #calcualte log_prob_data: log P(X_1:n=x_1:n | theta) scalar\n",
    "    #calculate log_gammas: log P(Z_i=k | X_i=x_i, theta) N by K\n",
    "    weighted_log_prob = np.zeros((N,K))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ######### end of modification #########\n",
    "    return log_gammas, log_prob_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c1b86",
   "metadata": {},
   "source": [
    "# implementation EM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7701c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM(X, K = 2, max_iter = 100, tol = 10**(-4), n_init = 3, debug = False):\n",
    "    \n",
    "    N, M = X.shape \n",
    "    res = {}\n",
    "    best_log_prob_data = -np.inf\n",
    "    converged  = False \n",
    "\n",
    "    #loop through different random starting points\n",
    "    for init in range(1, 1+n_init, 1):\n",
    "        np.random.seed(init)\n",
    "        if(debug):\n",
    "            print(f\"starting EM on random initialization: {init} out of {n_init}\")\n",
    "        \n",
    "        ######### TODO 3c: modify the following to have the full EM updates #########\n",
    "        \n",
    "        #initialize soft assignment \n",
    "        gammas = None\n",
    "        \n",
    "    \n",
    "        \n",
    "        log_prob_data  = -np.inf\n",
    "        for n_iter in range(1, 1+max_iter, 1):\n",
    "            prev_log_prob_data = log_prob_data\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            ######### convergence check #########\n",
    "            change = (log_prob_data - prev_log_prob_data)/N\n",
    "            if abs(change) < tol:\n",
    "                if(debug):\n",
    "                    print(f\"random initialization {init} converged at iteration {n_iter}\")\n",
    "                    print(\"\")\n",
    "                converged = True\n",
    "                break\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        ######### update on the best initialization #########\n",
    "        best_init = NULL\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ######### end of modification #########\n",
    "    res[\"converged\"] = converged     \n",
    "    res[\"best_init\"] = best_init\n",
    "    return(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
