# Model training (Random Forest example)
model <- randomForest(phenotypes ~ ., data = train_data, ntree = 100, importance = TRUE)
# Model training (Random Forest example)
model <- randomForest(as.matrix(phenotypes) ~ ., data = train_data, ntree = 100, importance = TRUE)
# Model training (Random Forest example)
model <- randomForest(phenotypes ~ ., data = train_data, ntree = 100, importance = TRUE)
# Model training (Random Forest example)
model <- randomForest(phenotypes ~ ., data = train_data, ntree = 100, importance = TRUE)
# Model prediction on the validation set
predictions <- predict(model, newdata = val_data)
val_data <- combined_data[-indices, ]
# Model training (Random Forest example)
model <- randomForest(phenotypes ~ ., data = train_data, ntree = 100, importance = TRUE)
# Model prediction on the validation set
predictions <- predict(model, newdata = val_data)
# Evaluation on the validation set
r_squared <- 1 - mean((val_data$phenotypes - predictions)^2) / var(val_data$phenotypes)
# Prediction on the test data
test_predictions <- predict(model, newdata = test_data)
# Save predictions to a CSV file
test_data$predicted_phenotype <- test_predictions
write.csv(test_data, "predicted_phenotypes.csv", row.names = FALSE)
test_data <- read.csv("test.genotype.txt")
# Feature engineering (quadratic features for each SNP)
for (col in colnames(genetic_data)) {
# Check if the column is numeric before applying the square operation
if (is.numeric(genetic_data[[col]])) {
genetic_data[paste0(col, "_squared")] <- genetic_data[[col]]^2
test_data[paste0(col, "_squared")] <- test_data[[col]]^2
}
}
# Split data into training and validation sets
set.seed(42)  # for reproducibility
indices <- sample(1:nrow(genetic_data), 0.8 * nrow(genetic_data))
train_data <- genetic_data[indices, ]
val_data <- genetic_data[-indices, ]
train_phenotypes <- phenotypes[indices, ]
val_phenotypes <- phenotypes[-indices, ]
# Model training (Random Forest example)
model <- randomForest(train_phenotypes ~ ., data = train_data, ntree = 100, importance = TRUE)
val_data <- genetic_data[-indices, ]
train_phenotypes <- phenotypes[indices, ]
val_phenotypes <- phenotypes[-indices, ]
# Model training (Random Forest example)
model <- randomForest(train_phenotypes ~ ., data = train_data, ntree = 100, importance = TRUE)
# Feature engineering (quadratic features for each SNP)
for (col in colnames(genetic_data)) {
# Check if the column is numeric before applying the square operation
if (is.numeric(genetic_data[[col]])) {
genetic_data[paste0(col, "_squared")] <- genetic_data[[col]]^2
test_data[paste0(col, "_squared")] <- test_data[[col]]^2
}
}
rm(list = ls())
# Load required libraries
library(randomForest)
# Load data
genetic_data <- read.csv("train.genotype.txt")
phenotypes <- read.csv("train.phenotype.txt")
test_data <- read.csv("test.genotype.txt")
# Feature engineering (quadratic features for each SNP)
for (col in colnames(genetic_data)) {
# Check if the column is numeric before applying the square operation
if (is.numeric(genetic_data[[col]])) {
genetic_data[paste0(col, "_squared")] <- genetic_data[[col]]^2
test_data[paste0(col, "_squared")] <- test_data[[col]]^2
}
}
# Combine genetic data with phenotypes
combined_data <- cbind(phenotypes, genetic_data)
# Split data into training and validation sets
set.seed(42)  # for reproducibility
# Load data
genetic_data <- read.csv("train.genotype.txt")
phenotypes <- read.csv("train.phenotype.txt")
test_data <- read.csv("test.genotype.txt")
# Feature engineering (quadratic features for each SNP)
for (col in colnames(genetic_data)) {
# Check if the column is numeric before applying the square operation
if (is.numeric(genetic_data[[col]])) {
genetic_data[paste0(col, "_squared")] <- genetic_data[[col]]^2
test_data[paste0(col, "_squared")] <- test_data[[col]]^2
}
}
# Combine genetic data with phenotypes
combined_data <- cbind(phenotypes, genetic_data)
# Split data into training and validation sets
set.seed(42)  # for reproducibility
indices <- sample(1:nrow(combined_data), 0.8 * nrow(combined_data))
train_data <- combined_data[indices, ]
val_data <- combined_data[-indices, ]
# Model training (Random Forest example)
model <- randomForest(phenotypes ~ ., data = train_data, ntree = 100, importance = TRUE)
# Model training (Random Forest example)
model <- randomForest(as.matrix(phenotypes) ~ ., data = train_data, ntree = 100, importance = TRUE)
View(combined_data)
View(phenotypes)
# Model training (Random Forest example)
model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 100, importance = TRUE)
# Model prediction on the validation set
predictions <- predict(model, newdata = val_data)
# Evaluation on the validation set
r_squared <- 1 - mean((val_data$phenotypes - predictions)^2) / var(val_data$phenotypes)
write.csv(predictions, "predicted_phenotypes.csv", row.names = FALSE)
# Prediction on the test data
test_predictions <- predict(model, newdata = test_data)
# Evaluation on the validation set
r_squared <- 1 - mean((val_data$phenotypes - predictions)^2) / var(val_data$phenotypes)
# Model prediction on the validation set
predictions <- predict(model, newdata = val_data)
# Evaluation on the validation set
r_squared <- 1 - mean((val_data$phenotypes - predictions)^2) / var(val_data$phenotypes)
View(val_data)
# Evaluation on the validation set
r_squared <- 1 - mean((val_data$X.1.445386 - predictions)^2) / var(val_data$phenotypes)
# Evaluation on the validation set
r_squared <- 1 - mean((val_data$X.1.445386 - predictions)^2) / var(val_data$phenotypes)
# Evaluation on the validation set
r_squared <- 1 - mean((val_data$X.1.445386 - predictions)^2) / var(val_data$X.1.445386)
cat("R-squared on validation set:", r_squared, "\n")
# Model training (Random Forest example)
model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 5, importance = TRUE)
# Combine genetic data with phenotypes
combined_data <- cbind(phenotypes, genetic_data)
# Split data into training and validation sets
set.seed(42)  # for reproducibility
indices <- sample(1:nrow(combined_data), 0.8 * nrow(combined_data))
train_data <- combined_data[indices, ]
val_data <- combined_data[-indices, ]
# Model training (Random Forest example)
model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 5, importance = TRUE)
# Model training (Random Forest example)
model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 400, mtry = 5, importance = TRUE)
ncol(train_data)
# Model training (Random Forest example)
model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 2, importance = TRUE)
# Model training (Random Forest example)
model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 1, importance = TRUE)
# Model prediction on the validation set
predictions <- predict(model, newdata = val_data)
# Evaluation on the validation set
r_squared <- 1 - mean((val_data$X.1.445386 - predictions)^2) / var(val_data$X.1.445386, na.rm = TRUE)
cat("R-squared on validation set:", r_squared, "\n")
# Model training (Random Forest example)
model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 1000, mtry = 1, importance = TRUE)
importance <- importance(model)
View(importance)
selected_features <- rownames(importance)[1:10]  # Adjust the number as needed
# Load required libraries
library(randomForest)
library(caret)
# Load data
genetic_data <- read.csv("train.genotype.txt")
phenotypes <- read.csv("train.phenotype.txt")
test_data <- read.csv("test.genotype.txt")
combined_data <- cbind(phenotypes, genetic_data)
# Split data into training and validation sets
set.seed(42)  # for reproducibility
indices <- sample(1:nrow(combined_data), 0.8 * nrow(combined_data))
train_data <- combined_data[indices, ]
val_data <- combined_data[-indices, ]
# Get the number of variables
num_variables <- ncol(train_data)
# Train a Random Forest model to get variable importance
rf_model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = min(10, num_variables), importance = TRUE)
# Train a Random Forest model to get variable importance
rf_model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 1, importance = TRUE)
# Get variable importance
importance <- importance(rf_model)
# Select the top features (adjust the number as needed)
selected_features <- rownames(importance)[1:10]
# Update the training and validation sets with selected features
train_data <- train_data[, c("X.1.445386", selected_features)]
PhenotypeColumn
# Train a Random Forest model to get variable importance
rf_model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 1, importance = TRUE)
# Get variable importance
importance <- importance(rf_model)
# Select the top features (adjust the number as needed)
selected_features <- rownames(importance)[1:10]
# Update the training and validation sets with selected features
train_data <- train_data[, c("PhenotypeColumn", selected_features)]
# Train a Random Forest model to get variable importance
rf_model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 1, importance = TRUE)
# Get variable importance
importance <- importance(rf_model)
# Select the top features (adjust the number as needed)
selected_features <- rownames(importance)[1:10]
# Update the training and validation sets with selected features
train_data <- train_data[, c("PhenotypeColumn", selected_features)]
val_data <- val_data[, c("PhenotypeColumn", selected_features)]
# Load required libraries
library(randomForest)
library(caret)
# Load data
genetic_data <- read.csv("train.genotype.txt")
phenotypes <- read.csv("train.phenotype.txt")
test_data <- read.csv("test.genotype.txt")
combined_data <- cbind(phenotypes, genetic_data)
# Split data into training and validation sets
set.seed(42)  # for reproducibility
indices <- sample(1:nrow(combined_data), 0.8 * nrow(combined_data))
train_data <- combined_data[indices, ]
val_data <- combined_data[-indices, ]
# Get the number of variables
num_variables <- ncol(train_data)
# Train a Random Forest model to get variable importance
rf_model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 1, importance = TRUE)
# Get variable importance
importance <- importance(rf_model)
# Select the top features (adjust the number as needed)
selected_features <- rownames(importance)[1:10]
# Update the training and validation sets with selected features
train_data <- train_data[, c("PhenotypeColumn", selected_features)]
# Update the training and validation sets with selected features
train_data <- train_data[, c("X.1.445386", selected_features)]
val_data <- val_data[, c("X.1.445386", selected_features)]
# Model training with the selected features
model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = min(10, length(selected_features)), importance = TRUE)
# Model prediction on the validation set
predictions <- predict(model, newdata = val_data)
# Model training with the selected features
model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 1, importance = TRUE)
# Model prediction on the validation set
predictions <- predict(model, newdata = val_data)
# Evaluation on the validation set
r_squared <- 1 - mean((val_data$PhenotypeColumn - predictions)^2) / var(val_data$PhenotypeColumn, na.rm = TRUE)
# Evaluation on the validation set
r_squared <- 1 - mean((val_data$X.1.445386 - predictions)^2) / var(val_data$PhenotypeColumn, na.rm = TRUE)
View(rf_model)
# Load data
genetic_data <- read.csv("train.genotype.txt")
phenotypes <- read.csv("train.phenotype.txt")
test_data <- read.csv("test.genotype.txt")
combined_data <- cbind(phenotypes, genetic_data)
# Split data into training and validation sets
set.seed(42)  # for reproducibility
View(combined_data)
# Load data
genetic_data <- read.csv("train.genotype.txt", sep = " ")
phenotypes <- read.csv("train.phenotype.txt")
test_data <- read.csv("test.genotype.txt", sep = " ")
combined_data <- cbind(phenotypes, genetic_data)
View(combined_data)
# Split data into training and validation sets
set.seed(42)  # for reproducibility
indices <- sample(1:nrow(combined_data), 0.8 * nrow(combined_data))
train_data <- combined_data[indices, ]
val_data <- combined_data[-indices, ]
# Get the number of variables
num_variables <- ncol(train_data)
# Train a Random Forest model to get variable importance
rf_model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 1, importance = TRUE)
# Train a Random Forest model to get variable importance
rf_model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 10, importance = TRUE)
# Get variable importance
importance <- importance(rf_model)
# Select the top features (adjust the number as needed)
selected_features <- rownames(importance)[1:10]
# Update the training and validation sets with selected features
train_data <- train_data[, c("X.1.445386", selected_features)]
val_data <- val_data[, c("X.1.445386", selected_features)]
View(train_data)
# Model training with the selected features
model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 1, importance = TRUE)
# Model prediction on the validation set
predictions <- predict(model, newdata = val_data)
# Evaluation on the validation set
r_squared <- 1 - mean((val_data$X.1.445386 - predictions)^2) / var(val_data$X.1.445386, na.rm = TRUE)
cat("R-squared on validation set:", r_squared, "\n")
# Model training with the selected features
model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 10, importance = TRUE)
# Model prediction on the validation set
predictions <- predict(model, newdata = val_data)
# Evaluation on the validation set
r_squared <- 1 - mean((val_data$X.1.445386 - predictions)^2) / var(val_data$X.1.445386, na.rm = TRUE)
cat("R-squared on validation set:", r_squared, "\n")
# Train a Random Forest model to get variable importance
rf_model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 20, importance = TRUE)
# Train a Random Forest model to get variable importance
rf_model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 10, importance = TRUE)
# Get variable importance
importance <- importance(rf_model)
# Select the top features (adjust the number as needed)
selected_features <- rownames(importance)[1:10]
# Select the top features (adjust the number as needed)
selected_features <- rownames(importance)[1:20]
View(train_data)
# Update the training and validation sets with selected features
train_data <- train_data[, c("X.1.445386", selected_features)]
# Get variable importance
importance <- importance(rf_model)
# Select the top features (adjust the number as needed)
selected_features <- rownames(importance)[1:10]
# Update the training and validation sets with selected features
train_data <- train_data[, c("X.1.445386", selected_features)]
val_data <- val_data[, c("X.1.445386", selected_features)]
# Model training with the selected features
model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 20, importance = TRUE)
# Model training with the selected features
model <- randomForest(X.1.445386 ~ ., data = train_data, ntree = 500, mtry = 10, importance = TRUE)
# Model prediction on the validation set
predictions <- predict(model, newdata = val_data)
# Evaluation on the validation set
r_squared <- 1 - mean((val_data$X.1.445386 - predictions)^2) / var(val_data$X.1.445386, na.rm = TRUE)
cat("R-squared on validation set:", r_squared, "\n")
# Prediction on the test data
test_predictions <- predict(model, newdata = test_data[, selected_features])
# Save predictions to a CSV file
test_data$predicted_phenotype <- test_predictions
write.csv(test_data, "predicted_phenotypes.csv", row.names = FALSE)
write.csv(test_predictions, "predicted_phenotypes.csv", row.names = FALSE)
write.csv(test_predictions, "predicted_phenotypes.csv", row.names = FALSE)
rm(list = ls())
# Load data
genetic_data <- read.csv("train.genotype.txt", sep = " ")
phenotypes <- read.csv("train.phenotype.txt")
test_data <- read.csv("test.genotype.txt", sep = " ")
library(glmnet)
combined_data <- cbind(phenotypes, genetic_data)
View(combined_data)
X <- as.matrix(combined_data[, -1])
View(X)
y <- combined_data$phenotypes
View(phenotypes)
y <- combined_data$X.1.445386
lasso_model <- cv.glmnet(X, y, alpha = 1)
View(lasso_model)
selected_features <- coef(lasso_model, s = "lambda.min")[, 1]
selected_features <- names(selected_features[selected_features != 0])
selected_data <- combined_data[, c("phenotypes", selected_features)]
selected_data <- combined_data[, c("X.1.445386", selected_features)]
selected_data <- combined_data[, c("phenotypes", selected_features)]
selected_data <- combined_data[, c("X.1.445386", selected_features)]
selected features
selected_features
selected_features <- coef(lasso_model, s = "lambda.min")[, 1]
selected_featuress <- names(selected_features[selected_features != 0])
colnames(combined_data)
selected_data <- combined_data[, c("X.1.445386", selected_features)]
lasso_model <- cv.glmnet(X, y, alpha = 0.5)
selected_features <- coef(lasso_model, s = "lambda.min")[, 1]
selected_featuress <- names(selected_features[selected_features != 0])
selected_data <- combined_data[, c("X.1.445386", selected_features)]
selected_data <- combined_data[, c(X.1.445386, selected_features)]
selected_data <- combined_data[, c("X.1.445386", selected_featuress)]
selected_featuress
selected_data <- combined_data[, c(, selected_featuress)]
combined_data <- cbind(phenotypes, genetic_data)
# Get the number of SNPs in your data
num_snps <- ncol(combined_data) - 1  # Assuming the last column is the target variable
# Create new column names
new_column_names <- c("phenotypes", paste0("SNP", 1:num_snps))
# Update column names in 'combined_data'
colnames(combined_data) <- new_column_names
# Verify the updated column names
colnames(combined_data)
X <- as.matrix(combined_data[, -1])
y <- combined_data$phenotypes
lasso_model <- cv.glmnet(X, y, alpha = 0.5)
selected_features <- coef(lasso_model, s = "lambda.min")[, 1]
selected_featuress <- names(selected_features[selected_features != 0])
selected_data <- combined_data[, c("phenotypes", selected_featuress)]
selected_featuress
combined_data[,2]
selected_featuress <- names(selected_features[selected_features != 0])
selected_data <- cbind(phenotypes, combined_data[,2],combined_data[,8],combined_data[,19],combined_data[,24])
selected_data <- cbind(selected_data, combined_data[,33],combined_data[,35],combined_data[,47],combined_data[,51])
selected_data <- cbind(selected_data, combined_data[,55],combined_data[,56],combined_data[,59],combined_data[,61])
selected_data <- cbind(selected_data, combined_data[,71],combined_data[,90],combined_data[,91],combined_data[,103])
selected_data <- cbind(selected_data, combined_data[,105],combined_data[,118],combined_data[,128],combined_data[,133])
selected_data <- cbind(selected_data, combined_data[,134],combined_data[,149],combined_data[,150],combined_data[,153])
selected_data <- cbind(selected_data, combined_data[,157],combined_data[,164],combined_data[,165],combined_data[,179])
selected_data <- cbind(selected_data, combined_data[,188])
View(selected_data)
linear_model <- lm(X.1.445386 ~ ., data = selected_data)
summary(linear_model)
test_combined_data <- cbind(test_data$phenotypes, test_data[, selected_features])
View(test_data)
View(genetic_data)
test_selected_data<- cbind(test_data[,1],test_data[,7],test_data[,18],test_data[,23])
test_selected_data <- cbind(test_selected_data, test_data[,32],test_data[,34],test_data[,46],test_data[,50])
test_selected_data <- cbind(test_selected_data, test_data[,54],test_data[,55],test_data[,58],test_data[,60])
test_selected_data <- cbind(test_selected_data, test_data[,70],test_data[,89],test_data[,90],test_data[,102])
test_selected_data <- cbind(test_selected_data, test_data[,104],test_data[,117],test_data[,127],test_data[,132])
test_selected_data <- cbind(test_selected_data, test_data[,133],test_data[,148],test_data[,149],test_data[,152])
test_selected_data <- cbind(test_selected_data, test_data[,156],test_data[,163],test_data[,164],test_data[,178])
test_selected_data <- cbind(test_selected_data, test_data[,187])
# Verify the updated column names
colnames(test_combined_data)
# Make predictions on the test data
test_predictions <- predict(linear_model, newdata = test_selected_data)
frame <- data.frame(test_selected_data)
# Make predictions on the test data
test_predictions <- predict(linear_model, newdata = test_selected_data)
# Make predictions on the test data
test_predictions <- predict(linear_model, newdata = frame)
View(linear_model)
summary(linear_model)
# Make predictions on the test data
test_predictions <- predict(linear_model, newdata = frame)
colnames(frames) <- c("phenotypes", paste0("SNP", 1:length(selected_features)))
frames <- data.frame(test_selected_data)
colnames(frames) <- c("phenotypes", paste0("SNP", 1:length(selected_features)))
colnames(test_selected_data) <- c("phenotypes", paste0("SNP", 1:length(selected_features)))
View(frame)
# Make predictions on the test data
test_predictions <- predict(linear_model, newdata = frame)
test_combined_data <- test_data[, c("phenotypes", selected_features)]
View(test_data)
test_predictions <- predict(linear_model, newdata = test_selected_data)
test_predictions <- predict(linear_model, newdata = data.frame(test_selected_data))
linear_model
test_data_selected <- test_data[, selected_features]
colnames(test_data_selected) <- paste0("SNP", 1:length(selected_features))
View(test_data_selected)
coles<-c(paste0("SNP",1:num_snps))
colnames(test_data) <- coles
View(selected_data)
View(test_data)
test_data_selected <- test_data[, selected_features]
colnames(test_data_selected) <- paste0("SNP", 1:length(selected_features))
View(test_data_selected)
View(test_data)
test_selected_data<- cbind(test_data[,1],test_data[,7],test_data[,18],test_data[,23])
test_selected_data <- cbind(test_selected_data, test_data[,32],test_data[,34],test_data[,46],test_data[,50])
test_selected_data <- cbind(test_selected_data, test_data[,54],test_data[,55],test_data[,58],test_data[,60])
test_selected_data <- cbind(test_selected_data, test_data[,70],test_data[,89],test_data[,90],test_data[,102])
test_selected_data <- cbind(test_selected_data, test_data[,104],test_data[,117],test_data[,127],test_data[,132])
test_selected_data <- cbind(test_selected_data, test_data[,133],test_data[,148],test_data[,149],test_data[,152])
test_selected_data <- cbind(test_selected_data, test_data[,156],test_data[,163],test_data[,164],test_data[,178])
test_selected_data <- cbind(test_selected_data, test_data[,187])
test_predictions <- predict(linear_model, newdata = data.frame(test_selected_data))
View(test_data_selected)
View(test_selected_data)
test_predictions <- predict(linear_model, newdata = data.frame(test_selected_data))
test_predictions <- predict(linear_model, newdata = as.matrix.data.frame(test_selected_data))
test_predictions <- predict(linear_model, newdata = as.matrix(test_selected_data))
View(test_selected_data)
coefficients <- coef(linear_model)
intercept <- coefficients[1]
linear_combination <- as.matrix(test_features) %*% coefficients[-1] + intercept
test_features <- test_data[, selected_features]
linear_combination <- as.matrix(test_selected_data) %*% coefficients[-1] + intercept
predicted_phenotypes <- as.vector(linear_combination)
test_results <- data.frame(Phenotypes = predicted_phenotypes)
View(test_results)
print(test_results)
write.csv(test_results, "test_predictions.csv", row.names = FALSE)
# Load data
genetic_data <- read.csv("train.genotype.txt", sep = " ")
phenotypes <- read.csv("train.phenotype.txt")
test_data <- read.csv("test.genotype.txt", sep = " ")
combined_data <- cbind(phenotypes, genetic_data)
num_snps <- ncol(combined_data) - 1
new_column_names <- c("phenotypes", paste0("SNP", 1:num_snps))
coles<-c(paste0("SNP",1:num_snps))
colnames(combined_data) <- new_column_names
colnames(test_data) <- coles
#training
library(glmnet)
X <- as.matrix(combined_data[, -1])
y <- combined_data$phenotypes
lasso_model <- cv.glmnet(X, y, alpha = 1)
selected_features <- coef(lasso_model, s = "lambda.min")[, 1]
selected_featuress <- names(selected_features[selected_features != 0])
selected_featuress
# Load data
genetic_data <- read.csv("train.genotype.txt", sep = " ")
phenotypes <- read.csv("train.phenotype.txt")
test_data <- read.csv("test.genotype.txt", sep = " ")
combined_data <- cbind(phenotypes, genetic_data)
num_snps <- ncol(combined_data) - 1
new_column_names <- c("phenotypes", paste0("SNP", 1:num_snps))
coles<-c(paste0("SNP",1:num_snps))
colnames(combined_data) <- new_column_names
colnames(test_data) <- coles
#training
library(glmnet)
X <- as.matrix(combined_data[, -1])
y <- combined_data$phenotypes
lasso_model <- cv.glmnet(X, y, alpha = 1)
selected_features <- coef(lasso_model, s = "lambda.min")[, 1]
selected_featuress <- names(selected_features[selected_features != 0])
selected_featuress
lasso_model <- cv.glmnet(X, y, alpha = 1)
selected_features <- coef(lasso_model, s = "lambda.min")[, 1]
selected_featuress <- names(selected_features[selected_features != 0])
selected_featuress
lasso_model <- cv.glmnet(X, y, alpha = 0.5)
selected_features <- coef(lasso_model, s = "lambda.min")[, 1]
selected_featuress <- names(selected_features[selected_features != 0])
selected_featuress
rm(list = ls())
# Load data
genetic_data <- read.csv("train.genotype.txt", sep = " ")
phenotypes <- read.csv("train.phenotype.txt")
test_data <- read.csv("test.genotype.txt", sep = " ")
combined_data <- cbind(phenotypes, genetic_data)
num_snps <- ncol(combined_data) - 1
new_column_names <- c("phenotypes", paste0("SNP", 1:num_snps))
coles<-c(paste0("SNP",1:num_snps))
colnames(combined_data) <- new_column_names
colnames(test_data) <- coles
#training
library(glmnet)
X <- as.matrix(combined_data[, -1])
y <- combined_data$phenotypes
lasso_model <- cv.glmnet(X, y, alpha = 0.5)
selected_features <- coef(lasso_model, s = "lambda.min")[, 1]
selected_featuress <- names(selected_features[selected_features != 0])
selected_featuress
